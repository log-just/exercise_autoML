{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitvenvvirtualenvb0a517c4d1b542bf8fe57b3974d75173",
   "display_name": "Python 3.7.5 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n0            1         0       3    male  22.0      1      0   \n1            2         1       1  female  38.0      1      0   \n2            3         1       3  female  26.0      0      0   \n3            4         1       1  female  35.0      1      0   \n4            5         0       3    male  35.0      0      0   \n\n             Ticket     Fare Cabin Embarked  \n0         A/5 21171   7.2500     0        S  \n1          PC 17599  71.2833   C85        C  \n2  STON/O2. 3101282   7.9250     0        S  \n3            113803  53.1000  C123        S  \n4            373450   8.0500     0        S  "
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('./titanic/train.csv')\n",
    "df_train = df_train.drop('Name', axis=1)\n",
    "df_train = df_train.fillna(0)\n",
    "# df_train = df_train.drop('Cabin', axis=1)\n",
    "df_train.head()\n",
    "#print(type(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>0</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>0</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>0</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Pclass     Sex   Age  SibSp  Parch   Ticket     Fare Cabin  \\\n0          892       3    male  34.5      0      0   330911   7.8292     0   \n1          893       3  female  47.0      1      0   363272   7.0000     0   \n2          894       2    male  62.0      0      0   240276   9.6875     0   \n3          895       3    male  27.0      0      0   315154   8.6625     0   \n4          896       3  female  22.0      1      1  3101298  12.2875     0   \n\n  Embarked  \n0        Q  \n1        S  \n2        Q  \n3        S  \n4        S  "
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./titanic/test.csv\")\n",
    "df_test = df_test.drop('Name', axis=1)\n",
    "df_test = df_test.fillna(0)\n",
    "# df_test = df_test.drop('Cabin', axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nTrain for 23 steps, validate for 6 steps\nEpoch 1/1000\n 1/23 [>.............................] - ETA: 11s - loss: 6.0645 - accuracy: 0.40623/23 [==============================] - 1s 36ms/step - loss: 4.6841 - accuracy: 0.4881 - val_loss: 10.8528 - val_accuracy: 0.2865\nEpoch 2/1000\n 1/23 [>.............................] - ETA: 0s - loss: 14.7411 - accuracy: 0.50023/23 [==============================] - 0s 7ms/step - loss: 7.9597 - accuracy: 0.4404 - val_loss: 4.9217 - val_accuracy: 0.6461\nEpoch 3/1000\n 1/23 [>.............................] - ETA: 0s - loss: 3.2927 - accuracy: 0.4323/23 [==============================] - 0s 3ms/step - loss: 2.0868 - accuracy: 0.4923 - val_loss: 4.2186 - val_accuracy: 0.3202\nEpoch 4/1000\n 1/23 [>.............................] - ETA: 0s - loss: 2.5694 - accuracy: 0.4619/23 [=======================>......] - ETA: 0s - loss: 2.0494 - accuracy: 0.5123/23 [==============================] - 0s 4ms/step - loss: 1.9088 - accuracy: 0.5344 - val_loss: 4.5034 - val_accuracy: 0.3427\nEpoch 5/1000\n 1/23 [>.............................] - ETA: 0s - loss: 3.7469 - accuracy: 0.5323/23 [==============================] - 0s 4ms/step - loss: 2.0687 - accuracy: 0.5133 - val_loss: 3.1564 - val_accuracy: 0.2978\nEpoch 6/1000\n 1/23 [>.............................] - ETA: 0s - loss: 5.8748 - accuracy: 0.5023/23 [==============================] - 0s 8ms/step - loss: 2.3259 - accuracy: 0.5456 - val_loss: 1.6844 - val_accuracy: 0.6742\nEpoch 7/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.5525 - accuracy: 0.5022/23 [===========================>..] - ETA: 0s - loss: 0.9958 - accuracy: 0.5723/23 [==============================] - 0s 4ms/step - loss: 0.9780 - accuracy: 0.5792 - val_loss: 1.1443 - val_accuracy: 0.5449\nEpoch 8/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.4896 - accuracy: 0.5623/23 [==============================] - 0s 8ms/step - loss: 1.1717 - accuracy: 0.5386 - val_loss: 1.2023 - val_accuracy: 0.6854\nEpoch 9/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.2933 - accuracy: 0.5022/23 [===========================>..] - ETA: 0s - loss: 1.1719 - accuracy: 0.5823/23 [==============================] - 0s 4ms/step - loss: 1.1566 - accuracy: 0.5820 - val_loss: 1.9712 - val_accuracy: 0.6854\nEpoch 10/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.9592 - accuracy: 0.6223/23 [==============================] - 0s 4ms/step - loss: 0.8506 - accuracy: 0.6185 - val_loss: 1.0395 - val_accuracy: 0.6854\nEpoch 11/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.7544 - accuracy: 0.5623/23 [==============================] - 0s 8ms/step - loss: 1.1740 - accuracy: 0.5554 - val_loss: 0.8110 - val_accuracy: 0.6910\nEpoch 12/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.9518 - accuracy: 0.5623/23 [==============================] - 0s 4ms/step - loss: 1.1316 - accuracy: 0.5961 - val_loss: 1.6883 - val_accuracy: 0.6910\nEpoch 13/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.8646 - accuracy: 0.5623/23 [==============================] - 0s 4ms/step - loss: 0.8861 - accuracy: 0.6410 - val_loss: 1.0234 - val_accuracy: 0.6910\nEpoch 14/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.2330 - accuracy: 0.5923/23 [==============================] - 0s 8ms/step - loss: 1.0749 - accuracy: 0.5638 - val_loss: 0.7911 - val_accuracy: 0.6966\nEpoch 15/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.8645 - accuracy: 0.4619/23 [=======================>......] - ETA: 0s - loss: 1.0298 - accuracy: 0.5923/23 [==============================] - 0s 5ms/step - loss: 1.0259 - accuracy: 0.5989 - val_loss: 1.7224 - val_accuracy: 0.6910\nEpoch 16/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.3628 - accuracy: 0.5923/23 [==============================] - 0s 8ms/step - loss: 1.2476 - accuracy: 0.6045 - val_loss: 1.1737 - val_accuracy: 0.7079\nEpoch 17/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.9089 - accuracy: 0.5923/23 [==============================] - 0s 4ms/step - loss: 1.1785 - accuracy: 0.6185 - val_loss: 1.2740 - val_accuracy: 0.6854\nEpoch 18/1000\n 1/23 [>.............................] - ETA: 0s - loss: 3.7048 - accuracy: 0.5023/23 [==============================] - 0s 4ms/step - loss: 2.8320 - accuracy: 0.5596 - val_loss: 0.9368 - val_accuracy: 0.6910\nEpoch 19/1000\n 1/23 [>.............................] - ETA: 0s - loss: 2.3745 - accuracy: 0.5623/23 [==============================] - 0s 4ms/step - loss: 1.8213 - accuracy: 0.5568 - val_loss: 1.2899 - val_accuracy: 0.5225\nEpoch 20/1000\n 1/23 [>.............................] - ETA: 0s - loss: 3.8916 - accuracy: 0.5322/23 [===========================>..] - ETA: 0s - loss: 1.6543 - accuracy: 0.5823/23 [==============================] - 0s 4ms/step - loss: 1.6860 - accuracy: 0.5835 - val_loss: 1.7524 - val_accuracy: 0.6798\nEpoch 21/1000\n 1/23 [>.............................] - ETA: 0s - loss: 2.8114 - accuracy: 0.5618/23 [======================>.......] - ETA: 0s - loss: 1.3282 - accuracy: 0.6323/23 [==============================] - 0s 5ms/step - loss: 1.2442 - accuracy: 0.6283 - val_loss: 1.4662 - val_accuracy: 0.6742\nEpoch 22/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.2620 - accuracy: 0.5323/23 [==============================] - 0s 8ms/step - loss: 1.1919 - accuracy: 0.6213 - val_loss: 0.8001 - val_accuracy: 0.7303\nEpoch 23/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.5785 - accuracy: 0.5022/23 [===========================>..] - ETA: 0s - loss: 1.5572 - accuracy: 0.6023/23 [==============================] - 0s 4ms/step - loss: 1.5064 - accuracy: 0.6031 - val_loss: 2.3414 - val_accuracy: 0.3483\nEpoch 24/1000\n 1/23 [>.............................] - ETA: 0s - loss: 2.3387 - accuracy: 0.5323/23 [==============================] - 0s 4ms/step - loss: 1.4730 - accuracy: 0.5905 - val_loss: 1.1275 - val_accuracy: 0.6236\n"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 97ee18b56fe34ce244b17c9e0f9041da</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.7303370833396912</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-optimizer: adam</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Oracle triggered exit\nTrain for 29 steps, validate for 6 steps\nEpoch 1/1000\n 1/29 [>.............................] - ETA: 14s - loss: 6.6441 - accuracy: 0.50027/29 [==========================>...] - ETA: 0s - loss: 4.7278 - accuracy: 0.5629/29 [==============================] - 1s 26ms/step - loss: 4.5492 - accuracy: 0.5690 - val_loss: 1.7410 - val_accuracy: 0.6910\nEpoch 2/1000\n 1/29 [>.............................] - ETA: 0s - loss: 2.3364 - accuracy: 0.5623/29 [======================>.......] - ETA: 0s - loss: 3.8136 - accuracy: 0.5229/29 [==============================] - 0s 4ms/step - loss: 3.4187 - accuracy: 0.5320 - val_loss: 1.8213 - val_accuracy: 0.6910\nEpoch 3/1000\n 1/29 [>.............................] - ETA: 0s - loss: 3.3171 - accuracy: 0.5024/29 [=======================>......] - ETA: 0s - loss: 1.8932 - accuracy: 0.5929/29 [==============================] - 0s 4ms/step - loss: 1.7938 - accuracy: 0.5903 - val_loss: 1.1497 - val_accuracy: 0.6966\nEpoch 4/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.3359 - accuracy: 0.5024/29 [=======================>......] - ETA: 0s - loss: 1.5928 - accuracy: 0.5329/29 [==============================] - 0s 4ms/step - loss: 1.5321 - accuracy: 0.5522 - val_loss: 1.0067 - val_accuracy: 0.6517\nEpoch 5/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.3418 - accuracy: 0.4623/29 [======================>.......] - ETA: 0s - loss: 1.4255 - accuracy: 0.5429/29 [==============================] - 0s 4ms/step - loss: 1.3534 - accuracy: 0.5612 - val_loss: 0.9876 - val_accuracy: 0.6854\nEpoch 6/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.0389 - accuracy: 0.4621/29 [====================>.........] - ETA: 0s - loss: 1.2506 - accuracy: 0.5429/29 [==============================] - 0s 4ms/step - loss: 1.1476 - accuracy: 0.5769 - val_loss: 0.8796 - val_accuracy: 0.7079\nEpoch 7/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8433 - accuracy: 0.5623/29 [======================>.......] - ETA: 0s - loss: 1.0164 - accuracy: 0.5729/29 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.5971 - val_loss: 0.7510 - val_accuracy: 0.7135\nEpoch 8/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8054 - accuracy: 0.5318/29 [=================>............] - ETA: 0s - loss: 1.0224 - accuracy: 0.5429/29 [==============================] - 0s 4ms/step - loss: 0.9032 - accuracy: 0.5892 - val_loss: 0.6635 - val_accuracy: 0.7135\nEpoch 9/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.0691 - accuracy: 0.5627/29 [==========================>...] - ETA: 0s - loss: 0.9178 - accuracy: 0.5629/29 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.5746 - val_loss: 0.6035 - val_accuracy: 0.7022\nEpoch 10/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.2510 - accuracy: 0.5023/29 [======================>.......] - ETA: 0s - loss: 0.8775 - accuracy: 0.5629/29 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.5892 - val_loss: 0.5747 - val_accuracy: 0.7135\nEpoch 11/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.2323 - accuracy: 0.5324/29 [=======================>......] - ETA: 0s - loss: 0.8106 - accuracy: 0.6029/29 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.6105 - val_loss: 0.5569 - val_accuracy: 0.7135\nEpoch 12/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.0600 - accuracy: 0.5026/29 [=========================>....] - ETA: 0s - loss: 0.7256 - accuracy: 0.6129/29 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.6229 - val_loss: 0.5489 - val_accuracy: 0.7191\nEpoch 13/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8505 - accuracy: 0.5627/29 [==========================>...] - ETA: 0s - loss: 0.6868 - accuracy: 0.6329/29 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.6397 - val_loss: 0.5341 - val_accuracy: 0.7360\nEpoch 14/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8254 - accuracy: 0.5028/29 [===========================>..] - ETA: 0s - loss: 0.6709 - accuracy: 0.6529/29 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.6588 - val_loss: 0.5331 - val_accuracy: 0.7528\nEpoch 15/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.7278 - accuracy: 0.5324/29 [=======================>......] - ETA: 0s - loss: 0.6859 - accuracy: 0.6429/29 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6510 - val_loss: 0.5248 - val_accuracy: 0.7416\nEpoch 16/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.7643 - accuracy: 0.5023/29 [======================>.......] - ETA: 0s - loss: 0.7145 - accuracy: 0.6429/29 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.6465 - val_loss: 0.5316 - val_accuracy: 0.7528\nEpoch 17/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.7939 - accuracy: 0.5323/29 [======================>.......] - ETA: 0s - loss: 0.7549 - accuracy: 0.6229/29 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.6308 - val_loss: 0.5850 - val_accuracy: 0.7360\nEpoch 18/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.7622 - accuracy: 0.5322/29 [=====================>........] - ETA: 0s - loss: 0.7250 - accuracy: 0.6429/29 [==============================] - 0s 4ms/step - loss: 0.7129 - accuracy: 0.6510 - val_loss: 0.5691 - val_accuracy: 0.7360\nEpoch 19/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.0537 - accuracy: 0.5020/29 [===================>..........] - ETA: 0s - loss: 0.8256 - accuracy: 0.6429/29 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.6510 - val_loss: 0.5309 - val_accuracy: 0.7472\nEpoch 20/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8580 - accuracy: 0.5622/29 [=====================>........] - ETA: 0s - loss: 0.8312 - accuracy: 0.6329/29 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.6622 - val_loss: 0.5092 - val_accuracy: 0.7528\nEpoch 21/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.8943 - accuracy: 0.4322/29 [=====================>........] - ETA: 0s - loss: 0.8573 - accuracy: 0.6229/29 [==============================] - 0s 4ms/step - loss: 0.8047 - accuracy: 0.6453 - val_loss: 0.5312 - val_accuracy: 0.7303\nEpoch 22/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6712 - accuracy: 0.6525/29 [========================>.....] - ETA: 0s - loss: 0.7857 - accuracy: 0.6729/29 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.6734 - val_loss: 0.5410 - val_accuracy: 0.7416\nEpoch 23/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6826 - accuracy: 0.5326/29 [=========================>....] - ETA: 0s - loss: 0.8797 - accuracy: 0.6329/29 [==============================] - 0s 4ms/step - loss: 0.8882 - accuracy: 0.6386 - val_loss: 0.8563 - val_accuracy: 0.7416\nEpoch 24/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.7292 - accuracy: 0.5924/29 [=======================>......] - ETA: 0s - loss: 0.6795 - accuracy: 0.6829/29 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.6824 - val_loss: 0.5686 - val_accuracy: 0.7360\nEpoch 25/1000\n 1/29 [>.............................] - ETA: 0s - loss: 1.0024 - accuracy: 0.5924/29 [=======================>......] - ETA: 0s - loss: 0.9534 - accuracy: 0.6129/29 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.6251 - val_loss: 0.7359 - val_accuracy: 0.6461\nEpoch 26/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6520 - accuracy: 0.6226/29 [=========================>....] - ETA: 0s - loss: 0.6710 - accuracy: 0.6729/29 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6790 - val_loss: 0.5176 - val_accuracy: 0.7528\nEpoch 27/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6217 - accuracy: 0.5927/29 [==========================>...] - ETA: 0s - loss: 0.6610 - accuracy: 0.6929/29 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6958 - val_loss: 0.5306 - val_accuracy: 0.7472\nEpoch 28/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6382 - accuracy: 0.6224/29 [=======================>......] - ETA: 0s - loss: 0.6453 - accuracy: 0.7029/29 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.7059 - val_loss: 0.5263 - val_accuracy: 0.7584\nEpoch 29/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6127 - accuracy: 0.5924/29 [=======================>......] - ETA: 0s - loss: 0.6602 - accuracy: 0.6729/29 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6857 - val_loss: 0.5580 - val_accuracy: 0.7528\nEpoch 30/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5868 - accuracy: 0.6522/29 [=====================>........] - ETA: 0s - loss: 0.6744 - accuracy: 0.6829/29 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7026 - val_loss: 0.5576 - val_accuracy: 0.7472\n"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "# Initialize the structured data classifier.\n",
    "clf = ak.StructuredDataClassifier(max_trials=1) # It tries 1 different models.\n",
    "# Feed the structured data classifier with training data.\n",
    "train_y = df_train.pop('Survived')\n",
    "clf.fit(x=df_train,y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
    }
   ],
   "source": [
    "preds = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv(\"./titanic/gender_submission.csv\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         1\n3          895         0\n4          896         0"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['Survived'] = preds\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"./titanic_submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}