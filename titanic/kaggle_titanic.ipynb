{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitvenvvirtualenvb0a517c4d1b542bf8fe57b3974d75173",
   "display_name": "Python 3.7.5 64-bit ('venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load data files & check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('./titanic/train.csv')\n",
    "df_test = pd.read_csv(\"./titanic/test.csv\")\n",
    "#print(type(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S\n(891, 12)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
    },
    {
     "data": {
      "text/plain": "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check train data\n",
    "print(df_train.head())\n",
    "print(df_train.shape)\n",
    "df_train.info()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S\n(418, 11)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n"
    },
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check test data\n",
    "print(df_test.head())\n",
    "print(df_test.shape)\n",
    "df_test.head()\n",
    "df_test.info()\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering\n",
    "### get 'title' from names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nCol           2\nMlle          2\nMajor         2\nCapt          1\nLady          1\nMs            1\nJonkheer      1\nDon           1\nSir           1\nMme           1\nCountess      1\nName: Title, dtype: int64\nMr        240\nMiss       78\nMrs        72\nMaster     21\nCol         2\nRev         2\nDr          1\nDona        1\nMs          1\nName: Title, dtype: int64\n"
    }
   ],
   "source": [
    "train_test_data = [df_train, df_test] # combining train and test dataset\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "print(df_train['Title'].value_counts())\n",
    "print(df_test['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mr           517\nMiss         183\nMrs          125\nGentleman     58\nunknown        6\nLady           2\nName: Title, dtype: int64\nMr           240\nMiss          79\nMrs           72\nGentleman     24\nunknown        2\nLady           1\nName: Title, dtype: int64\n"
    }
   ],
   "source": [
    "# map data with string (not number for test autoML performance)\n",
    "title_mapping = {\"Mr\": \"Mr\", \"Miss\": \"Miss\", \"Mrs\": \"Mrs\", \n",
    "                 \"Master\": \"Gentleman\", \"Dr\": \"Gentleman\", \"Rev\": \"Gentleman\", \"Col\": \"unknown\", \"Major\": \"Gentleman\", \"Mlle\": \"unknown\",\"Countess\": \"Lady\",\n",
    "                 \"Ms\": \"Miss\", \"Lady\": \"Lady\", \"Jonkheer\": \"unknown\", \"Don\": \"Gentleman\", \"Dona\" : \"Lady\", \"Mme\": \"unknown\",\"Capt\": \"Gentleman\",\"Sir\": \"Gentleman\" }\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "print(df_train['Title'].value_counts())\n",
    "print(df_test['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n0            1         0       3    male  22.0      1      0   \n1            2         1       1  female  38.0      1      0   \n2            3         1       3  female  26.0      0      0   \n3            4         1       1  female  35.0      1      0   \n4            5         0       3    male  35.0      0      0   \n\n             Ticket     Fare Cabin Embarked Title  \n0         A/5 21171   7.2500   NaN        S    Mr  \n1          PC 17599  71.2833   C85        C   Mrs  \n2  STON/O2. 3101282   7.9250   NaN        S  Miss  \n3            113803  53.1000  C123        S   Mrs  \n4            373450   8.0500   NaN        S    Mr  "
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete unnecessary feature from dataset\n",
    "df_train.drop('Name', axis=1, inplace=True)\n",
    "df_test.drop('Name', axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill missed age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for calculate overall statstics\n",
    "# (pd.merge(df_train,df_test)).head()\n",
    "## NEED INVESTGATE!\n",
    "# df_all = (pd.concat([df_train,df_test]))\n",
    "# df_all.info()\n",
    "\n",
    "# df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n0            1         0       3    male  22.0      1      0   \n1            2         1       1  female  38.0      1      0   \n2            3         1       3  female  26.0      0      0   \n3            4         1       1  female  35.0      1      0   \n4            5         0       3    male  35.0      0      0   \n\n             Ticket     Fare Cabin Embarked Title  \n0         A/5 21171   7.2500   NaN        S    Mr  \n1          PC 17599  71.2833   C85        C   Mrs  \n2  STON/O2. 3101282   7.9250   NaN        S  Miss  \n3            113803  53.1000  C123        S   Mrs  \n4            373450   8.0500   NaN        S    Mr  "
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test.groupby(\"Title\")[\"Age\"].transform(\"median\")\n",
    "# # fill missing age with median age for each title (Mr, Mrs, Miss, Others)\n",
    "df_train[\"Age\"].fillna(df_train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "df_test[\"Age\"].fillna(df_test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330877</td>\n      <td>8.4583</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17463</td>\n      <td>51.8625</td>\n      <td>E46</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Gentleman</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>347742</td>\n      <td>11.1333</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>PP 9549</td>\n      <td>16.7000</td>\n      <td>G6</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>58.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113783</td>\n      <td>26.5500</td>\n      <td>C103</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A/5. 2151</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>39.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>347082</td>\n      <td>31.2750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>350406</td>\n      <td>7.8542</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1</td>\n      <td>2</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248706</td>\n      <td>16.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>382652</td>\n      <td>29.1250</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Gentleman</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n      <td>2</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>244373</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>31.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>345763</td>\n      <td>18.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2649</td>\n      <td>7.2250</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>239865</td>\n      <td>26.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>1</td>\n      <td>2</td>\n      <td>male</td>\n      <td>34.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>248698</td>\n      <td>13.0000</td>\n      <td>D56</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330923</td>\n      <td>8.0292</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113788</td>\n      <td>35.5000</td>\n      <td>A6</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>8.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>349909</td>\n      <td>21.0750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>26</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>347077</td>\n      <td>31.3875</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2631</td>\n      <td>7.2250</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>28</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>19.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>19950</td>\n      <td>263.0000</td>\n      <td>C23 C25 C27</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>29</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330959</td>\n      <td>7.8792</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349216</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17601</td>\n      <td>27.7208</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Gentleman</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17569</td>\n      <td>146.5208</td>\n      <td>B78</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>33</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>335677</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>66.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C.A. 24579</td>\n      <td>10.5000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17604</td>\n      <td>82.1708</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>36</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>42.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113789</td>\n      <td>52.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>37</td>\n      <td>1</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2677</td>\n      <td>7.2292</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A./5. 2152</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>18.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>345764</td>\n      <td>18.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>40</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2651</td>\n      <td>11.2417</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>40.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7546</td>\n      <td>9.4750</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>0</td>\n      <td>2</td>\n      <td>female</td>\n      <td>27.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11668</td>\n      <td>21.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>43</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>349253</td>\n      <td>7.8958</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>1</td>\n      <td>2</td>\n      <td>female</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>SC/Paris 2123</td>\n      <td>41.5792</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330958</td>\n      <td>7.8792</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>46</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>S.C./A.4. 23567</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>47</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>370371</td>\n      <td>15.5000</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>48</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14311</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>49</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>30.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2662</td>\n      <td>21.6792</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>50</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>18.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>349237</td>\n      <td>17.8000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n0             1         0       3    male  22.0      1      0   \n1             2         1       1  female  38.0      1      0   \n2             3         1       3  female  26.0      0      0   \n3             4         1       1  female  35.0      1      0   \n4             5         0       3    male  35.0      0      0   \n5             6         0       3    male  30.0      0      0   \n6             7         0       1    male  54.0      0      0   \n7             8         0       3    male   2.0      3      1   \n8             9         1       3  female  27.0      0      2   \n9            10         1       2  female  14.0      1      0   \n10           11         1       3  female   4.0      1      1   \n11           12         1       1  female  58.0      0      0   \n12           13         0       3    male  20.0      0      0   \n13           14         0       3    male  39.0      1      5   \n14           15         0       3  female  14.0      0      0   \n15           16         1       2  female  55.0      0      0   \n16           17         0       3    male   2.0      4      1   \n17           18         1       2    male  30.0      0      0   \n18           19         0       3  female  31.0      1      0   \n19           20         1       3  female  35.0      0      0   \n20           21         0       2    male  35.0      0      0   \n21           22         1       2    male  34.0      0      0   \n22           23         1       3  female  15.0      0      0   \n23           24         1       1    male  28.0      0      0   \n24           25         0       3  female   8.0      3      1   \n25           26         1       3  female  38.0      1      5   \n26           27         0       3    male  30.0      0      0   \n27           28         0       1    male  19.0      3      2   \n28           29         1       3  female  21.0      0      0   \n29           30         0       3    male  30.0      0      0   \n30           31         0       1    male  40.0      0      0   \n31           32         1       1  female  35.0      1      0   \n32           33         1       3  female  21.0      0      0   \n33           34         0       2    male  66.0      0      0   \n34           35         0       1    male  28.0      1      0   \n35           36         0       1    male  42.0      1      0   \n36           37         1       3    male  30.0      0      0   \n37           38         0       3    male  21.0      0      0   \n38           39         0       3  female  18.0      2      0   \n39           40         1       3  female  14.0      1      0   \n40           41         0       3  female  40.0      1      0   \n41           42         0       2  female  27.0      1      0   \n42           43         0       3    male  30.0      0      0   \n43           44         1       2  female   3.0      1      2   \n44           45         1       3  female  19.0      0      0   \n45           46         0       3    male  30.0      0      0   \n46           47         0       3    male  30.0      1      0   \n47           48         1       3  female  21.0      0      0   \n48           49         0       3    male  30.0      2      0   \n49           50         0       3  female  18.0      1      0   \n\n              Ticket      Fare        Cabin Embarked      Title  \n0          A/5 21171    7.2500          NaN        S         Mr  \n1           PC 17599   71.2833          C85        C        Mrs  \n2   STON/O2. 3101282    7.9250          NaN        S       Miss  \n3             113803   53.1000         C123        S        Mrs  \n4             373450    8.0500          NaN        S         Mr  \n5             330877    8.4583          NaN        Q         Mr  \n6              17463   51.8625          E46        S         Mr  \n7             349909   21.0750          NaN        S  Gentleman  \n8             347742   11.1333          NaN        S        Mrs  \n9             237736   30.0708          NaN        C        Mrs  \n10           PP 9549   16.7000           G6        S       Miss  \n11            113783   26.5500         C103        S       Miss  \n12         A/5. 2151    8.0500          NaN        S         Mr  \n13            347082   31.2750          NaN        S         Mr  \n14            350406    7.8542          NaN        S       Miss  \n15            248706   16.0000          NaN        S        Mrs  \n16            382652   29.1250          NaN        Q  Gentleman  \n17            244373   13.0000          NaN        S         Mr  \n18            345763   18.0000          NaN        S        Mrs  \n19              2649    7.2250          NaN        C        Mrs  \n20            239865   26.0000          NaN        S         Mr  \n21            248698   13.0000          D56        S         Mr  \n22            330923    8.0292          NaN        Q       Miss  \n23            113788   35.5000           A6        S         Mr  \n24            349909   21.0750          NaN        S       Miss  \n25            347077   31.3875          NaN        S        Mrs  \n26              2631    7.2250          NaN        C         Mr  \n27             19950  263.0000  C23 C25 C27        S         Mr  \n28            330959    7.8792          NaN        Q       Miss  \n29            349216    7.8958          NaN        S         Mr  \n30          PC 17601   27.7208          NaN        C  Gentleman  \n31          PC 17569  146.5208          B78        C        Mrs  \n32            335677    7.7500          NaN        Q       Miss  \n33        C.A. 24579   10.5000          NaN        S         Mr  \n34          PC 17604   82.1708          NaN        C         Mr  \n35            113789   52.0000          NaN        S         Mr  \n36              2677    7.2292          NaN        C         Mr  \n37        A./5. 2152    8.0500          NaN        S         Mr  \n38            345764   18.0000          NaN        S       Miss  \n39              2651   11.2417          NaN        C       Miss  \n40              7546    9.4750          NaN        S        Mrs  \n41             11668   21.0000          NaN        S        Mrs  \n42            349253    7.8958          NaN        C         Mr  \n43     SC/Paris 2123   41.5792          NaN        C       Miss  \n44            330958    7.8792          NaN        Q       Miss  \n45   S.C./A.4. 23567    8.0500          NaN        S         Mr  \n46            370371   15.5000          NaN        Q         Mr  \n47             14311    7.7500          NaN        Q       Miss  \n48              2662   21.6792          NaN        C         Mr  \n49            349237   17.8000          NaN        S        Mrs  "
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "df_train[\"Fare\"].fillna(df_train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "df_test[\"Fare\"].fillna(df_test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "df_train.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# map to number\n",
    "cabin_mapping = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5, \"G\": 6, \"T\": 7}\n",
    "for dataset in train_test_data:\n",
    "    dataset[\"Cabin\"] = dataset[\"Cabin\"].str[:1]\n",
    "    dataset[\"Cabin\"] = dataset[\"Cabin\"].map(cabin_mapping)\n",
    "\n",
    "# fill missing Fare with median fare for each Pclass\n",
    "df_train[\"Cabin\"].fillna(df_train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n",
    "df_test[\"Cabin\"].fillna(df_test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplize family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"FamilySize\"] = df_train[\"SibSp\"] + df_train[\"Parch\"] + 1\n",
    "df_test[\"FamilySize\"] = df_test[\"SibSp\"] + df_test[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>5.0</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>2.0</td>\n      <td>C</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>5.0</td>\n      <td>S</td>\n      <td>Miss</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2.0</td>\n      <td>S</td>\n      <td>Mrs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>5.0</td>\n      <td>S</td>\n      <td>Mr</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Pclass     Sex   Age  SibSp  Parch     Fare  Cabin Embarked Title\n0       3    male  22.0      1      0   7.2500    5.0        S    Mr\n1       1  female  38.0      1      0  71.2833    2.0        C   Mrs\n2       3  female  26.0      0      0   7.9250    5.0        S  Miss\n3       1  female  35.0      1      0  53.1000    2.0        S   Mrs\n4       3    male  35.0      0      0   8.0500    5.0        S    Mr"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete unnecessary feature from dataset\n",
    "features_drop = ['PassengerId', 'Ticket', 'SibSp', 'Parch']\n",
    "df_train = df_train.drop(features_drop, axis=1)\n",
    "test = test.drop(features_drop, axis=1)\n",
    "\n",
    "df_train.drop('PassengerId', axis=1, inplace=True)\n",
    "df_test.drop('PassengerId', axis=1, inplace=True)\n",
    "df_train.drop('Ticket', axis=1, inplace=True)\n",
    "df_test.drop('Ticket', axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\nTrain for 23 steps, validate for 6 steps\nEpoch 1/1000\n 1/23 [>.............................] - ETA: 21s - loss: 3.0434 - accuracy: 0.50012/23 [==============>...............] - ETA: 0s - loss: 1.9199 - accuracy: 0.6023/23 [==============================] - 1s 65ms/step - loss: 1.5083 - accuracy: 0.6129 - val_loss: 0.8226 - val_accuracy: 0.4719\nEpoch 2/1000\n 1/23 [>.............................] - ETA: 0s - loss: 1.0207 - accuracy: 0.65 8/23 [=========>....................] - ETA: 0s - loss: 0.9357 - accuracy: 0.6413/23 [===============>..............] - ETA: 0s - loss: 0.9400 - accuracy: 0.6123/23 [==============================] - 0s 9ms/step - loss: 0.8394 - accuracy: 0.6424 - val_loss: 0.7919 - val_accuracy: 0.3820\nEpoch 3/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7262 - accuracy: 0.5911/23 [=============>................] - ETA: 0s - loss: 0.7178 - accuracy: 0.6419/23 [=======================>......] - ETA: 0s - loss: 0.7168 - accuracy: 0.6420/23 [=========================>....] - ETA: 0s - loss: 0.7118 - accuracy: 0.6523/23 [==============================] - 0s 20ms/step - loss: 0.7134 - accuracy: 0.6508 - val_loss: 0.7174 - val_accuracy: 0.6067\nEpoch 4/1000\n 1/23 [>.............................] - ETA: 1s - loss: 0.8002 - accuracy: 0.56 4/23 [====>.........................] - ETA: 0s - loss: 0.7301 - accuracy: 0.59 9/23 [==========>...................] - ETA: 0s - loss: 0.6867 - accuracy: 0.6519/23 [=======================>......] - ETA: 0s - loss: 0.6447 - accuracy: 0.6823/23 [==============================] - 0s 19ms/step - loss: 0.6438 - accuracy: 0.6830 - val_loss: 0.5854 - val_accuracy: 0.7247\nEpoch 5/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7006 - accuracy: 0.5911/23 [=============>................] - ETA: 0s - loss: 0.6378 - accuracy: 0.6623/23 [==============================] - 0s 6ms/step - loss: 0.6305 - accuracy: 0.6732 - val_loss: 0.5900 - val_accuracy: 0.7247\nEpoch 6/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7670 - accuracy: 0.5615/23 [==================>...........] - ETA: 0s - loss: 0.6421 - accuracy: 0.6823/23 [==============================] - 0s 16ms/step - loss: 0.6282 - accuracy: 0.6999 - val_loss: 0.5720 - val_accuracy: 0.7472\nEpoch 7/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7105 - accuracy: 0.62 5/23 [=====>........................] - ETA: 0s - loss: 0.6618 - accuracy: 0.6319/23 [=======================>......] - ETA: 0s - loss: 0.6080 - accuracy: 0.7023/23 [==============================] - 0s 9ms/step - loss: 0.6196 - accuracy: 0.7069 - val_loss: 0.5695 - val_accuracy: 0.7247\nEpoch 8/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7227 - accuracy: 0.65 5/23 [=====>........................] - ETA: 0s - loss: 0.6670 - accuracy: 0.6521/23 [==========================>...] - ETA: 0s - loss: 0.6088 - accuracy: 0.7023/23 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.7097 - val_loss: 0.5641 - val_accuracy: 0.7247\nEpoch 9/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7088 - accuracy: 0.65 4/23 [====>.........................] - ETA: 0s - loss: 0.6731 - accuracy: 0.6319/23 [=======================>......] - ETA: 0s - loss: 0.5976 - accuracy: 0.7123/23 [==============================] - 0s 9ms/step - loss: 0.6104 - accuracy: 0.7111 - val_loss: 0.5637 - val_accuracy: 0.7360\nEpoch 10/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7056 - accuracy: 0.65 4/23 [====>.........................] - ETA: 0s - loss: 0.6621 - accuracy: 0.6420/23 [=========================>....] - ETA: 0s - loss: 0.5961 - accuracy: 0.7123/23 [==============================] - 0s 15ms/step - loss: 0.6051 - accuracy: 0.7111 - val_loss: 0.5550 - val_accuracy: 0.7528\nEpoch 11/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.7009 - accuracy: 0.6515/23 [==================>...........] - ETA: 0s - loss: 0.6049 - accuracy: 0.6920/23 [=========================>....] - ETA: 0s - loss: 0.5887 - accuracy: 0.7123/23 [==============================] - 0s 9ms/step - loss: 0.5974 - accuracy: 0.7069 - val_loss: 0.5487 - val_accuracy: 0.7472\nEpoch 12/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6806 - accuracy: 0.6513/23 [===============>..............] - ETA: 0s - loss: 0.6071 - accuracy: 0.6821/23 [==========================>...] - ETA: 0s - loss: 0.5827 - accuracy: 0.7023/23 [==============================] - 0s 9ms/step - loss: 0.5916 - accuracy: 0.7069 - val_loss: 0.5424 - val_accuracy: 0.7472\nEpoch 13/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6757 - accuracy: 0.65 7/23 [========>.....................] - ETA: 0s - loss: 0.6187 - accuracy: 0.6623/23 [==============================] - 0s 7ms/step - loss: 0.5874 - accuracy: 0.7069 - val_loss: 0.5338 - val_accuracy: 0.7472\nEpoch 14/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6617 - accuracy: 0.6515/23 [==================>...........] - ETA: 0s - loss: 0.5864 - accuracy: 0.6923/23 [==============================] - 0s 13ms/step - loss: 0.5829 - accuracy: 0.7083 - val_loss: 0.5233 - val_accuracy: 0.7584\nEpoch 15/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6543 - accuracy: 0.6515/23 [==================>...........] - ETA: 0s - loss: 0.5816 - accuracy: 0.6923/23 [==============================] - 0s 6ms/step - loss: 0.5783 - accuracy: 0.7139 - val_loss: 0.5221 - val_accuracy: 0.7584\nEpoch 16/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6398 - accuracy: 0.6515/23 [==================>...........] - ETA: 0s - loss: 0.5762 - accuracy: 0.7023/23 [==============================] - 0s 13ms/step - loss: 0.5737 - accuracy: 0.7153 - val_loss: 0.5148 - val_accuracy: 0.7640\nEpoch 17/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6325 - accuracy: 0.6813/23 [===============>..............] - ETA: 0s - loss: 0.5775 - accuracy: 0.7019/23 [=======================>......] - ETA: 0s - loss: 0.5514 - accuracy: 0.7223/23 [==============================] - 0s 9ms/step - loss: 0.5678 - accuracy: 0.7209 - val_loss: 0.5096 - val_accuracy: 0.7640\nEpoch 18/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6200 - accuracy: 0.7114/23 [=================>............] - ETA: 0s - loss: 0.5718 - accuracy: 0.7023/23 [==============================] - 0s 14ms/step - loss: 0.5647 - accuracy: 0.7223 - val_loss: 0.5071 - val_accuracy: 0.7753\nEpoch 19/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6167 - accuracy: 0.6815/23 [==================>...........] - ETA: 0s - loss: 0.5601 - accuracy: 0.7216/23 [===================>..........] - ETA: 0s - loss: 0.5536 - accuracy: 0.7223/23 [==============================] - 0s 11ms/step - loss: 0.5601 - accuracy: 0.7335 - val_loss: 0.5033 - val_accuracy: 0.7697\nEpoch 20/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6075 - accuracy: 0.71 5/23 [=====>........................] - ETA: 0s - loss: 0.5788 - accuracy: 0.6719/23 [=======================>......] - ETA: 0s - loss: 0.5403 - accuracy: 0.7323/23 [==============================] - 0s 9ms/step - loss: 0.5570 - accuracy: 0.7279 - val_loss: 0.4979 - val_accuracy: 0.7640\nEpoch 21/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.6053 - accuracy: 0.7116/23 [===================>..........] - ETA: 0s - loss: 0.5466 - accuracy: 0.7323/23 [==============================] - 0s 7ms/step - loss: 0.5526 - accuracy: 0.7349 - val_loss: 0.4951 - val_accuracy: 0.7584\nEpoch 22/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5951 - accuracy: 0.7114/23 [=================>............] - ETA: 0s - loss: 0.5553 - accuracy: 0.7323/23 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7349 - val_loss: 0.4940 - val_accuracy: 0.7640\nEpoch 23/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5976 - accuracy: 0.7119/23 [=======================>......] - ETA: 0s - loss: 0.5291 - accuracy: 0.7423/23 [==============================] - 0s 7ms/step - loss: 0.5458 - accuracy: 0.7405 - val_loss: 0.4909 - val_accuracy: 0.7528\nEpoch 24/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5950 - accuracy: 0.7112/23 [==============>...............] - ETA: 0s - loss: 0.5508 - accuracy: 0.7323/23 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7461 - val_loss: 0.4885 - val_accuracy: 0.7584\nEpoch 25/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5901 - accuracy: 0.7118/23 [======================>.......] - ETA: 0s - loss: 0.5293 - accuracy: 0.7422/23 [===========================>..] - ETA: 0s - loss: 0.5260 - accuracy: 0.7423/23 [==============================] - 0s 7ms/step - loss: 0.5393 - accuracy: 0.7447 - val_loss: 0.4884 - val_accuracy: 0.7640\nEpoch 26/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5852 - accuracy: 0.7118/23 [======================>.......] - ETA: 0s - loss: 0.5264 - accuracy: 0.7423/23 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7447 - val_loss: 0.4871 - val_accuracy: 0.7640\nEpoch 27/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5863 - accuracy: 0.7116/23 [===================>..........] - ETA: 0s - loss: 0.5261 - accuracy: 0.7420/23 [=========================>....] - ETA: 0s - loss: 0.5234 - accuracy: 0.7423/23 [==============================] - 0s 9ms/step - loss: 0.5323 - accuracy: 0.7419 - val_loss: 0.4859 - val_accuracy: 0.7528\nEpoch 28/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5883 - accuracy: 0.71 7/23 [========>.....................] - ETA: 0s - loss: 0.5488 - accuracy: 0.7118/23 [======================>.......] - ETA: 0s - loss: 0.5209 - accuracy: 0.7423/23 [==============================] - 0s 10ms/step - loss: 0.5289 - accuracy: 0.7461 - val_loss: 0.4849 - val_accuracy: 0.7584\nEpoch 29/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5836 - accuracy: 0.7112/23 [==============>...............] - ETA: 0s - loss: 0.5305 - accuracy: 0.7323/23 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.7489 - val_loss: 0.4832 - val_accuracy: 0.7584\nEpoch 30/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5750 - accuracy: 0.7513/23 [===============>..............] - ETA: 0s - loss: 0.5282 - accuracy: 0.7423/23 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7532 - val_loss: 0.4836 - val_accuracy: 0.7528\nEpoch 31/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5824 - accuracy: 0.7516/23 [===================>..........] - ETA: 0s - loss: 0.5152 - accuracy: 0.7520/23 [=========================>....] - ETA: 0s - loss: 0.5131 - accuracy: 0.7523/23 [==============================] - 0s 9ms/step - loss: 0.5214 - accuracy: 0.7546 - val_loss: 0.4816 - val_accuracy: 0.7640\nEpoch 32/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5743 - accuracy: 0.75 7/23 [========>.....................] - ETA: 0s - loss: 0.5335 - accuracy: 0.7220/23 [=========================>....] - ETA: 0s - loss: 0.5103 - accuracy: 0.7523/23 [==============================] - 0s 9ms/step - loss: 0.5191 - accuracy: 0.7602 - val_loss: 0.4816 - val_accuracy: 0.7640\nEpoch 33/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5728 - accuracy: 0.7512/23 [==============>...............] - ETA: 0s - loss: 0.5191 - accuracy: 0.7523/23 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.7588 - val_loss: 0.4826 - val_accuracy: 0.7697\nEpoch 34/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5694 - accuracy: 0.7514/23 [=================>............] - ETA: 0s - loss: 0.5167 - accuracy: 0.7523/23 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7630 - val_loss: 0.4794 - val_accuracy: 0.7697\nEpoch 35/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5672 - accuracy: 0.7516/23 [===================>..........] - ETA: 0s - loss: 0.5049 - accuracy: 0.7623/23 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7630 - val_loss: 0.4825 - val_accuracy: 0.7697\nEpoch 36/1000\n 1/23 [>.............................] - ETA: 1s - loss: 0.5651 - accuracy: 0.75 9/23 [==========>...................] - ETA: 0s - loss: 0.5165 - accuracy: 0.7516/23 [===================>..........] - ETA: 0s - loss: 0.5053 - accuracy: 0.7623/23 [==============================] - 0s 10ms/step - loss: 0.5121 - accuracy: 0.7630 - val_loss: 0.4778 - val_accuracy: 0.7697\nEpoch 37/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5649 - accuracy: 0.7510/23 [============>.................] - ETA: 0s - loss: 0.5058 - accuracy: 0.7622/23 [===========================>..] - ETA: 0s - loss: 0.4963 - accuracy: 0.7623/23 [==============================] - 0s 10ms/step - loss: 0.5067 - accuracy: 0.7672 - val_loss: 0.4807 - val_accuracy: 0.7697\nEpoch 38/1000\n 1/23 [>.............................] - ETA: 1s - loss: 0.5643 - accuracy: 0.7111/23 [=============>................] - ETA: 0s - loss: 0.5084 - accuracy: 0.7513/23 [===============>..............] - ETA: 0s - loss: 0.5090 - accuracy: 0.7520/23 [=========================>....] - ETA: 0s - loss: 0.4982 - accuracy: 0.7623/23 [==============================] - 0s 12ms/step - loss: 0.5069 - accuracy: 0.7658 - val_loss: 0.4804 - val_accuracy: 0.7697\nEpoch 39/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5684 - accuracy: 0.7511/23 [=============>................] - ETA: 0s - loss: 0.5052 - accuracy: 0.7523/23 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.7630 - val_loss: 0.4796 - val_accuracy: 0.7753\nEpoch 40/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5686 - accuracy: 0.7112/23 [==============>...............] - ETA: 0s - loss: 0.5037 - accuracy: 0.7423/23 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7574 - val_loss: 0.4819 - val_accuracy: 0.7640\nEpoch 41/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5680 - accuracy: 0.6813/23 [===============>..............] - ETA: 0s - loss: 0.5064 - accuracy: 0.7422/23 [===========================>..] - ETA: 0s - loss: 0.4951 - accuracy: 0.7523/23 [==============================] - 0s 9ms/step - loss: 0.5049 - accuracy: 0.7560 - val_loss: 0.4816 - val_accuracy: 0.7697\nEpoch 42/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5741 - accuracy: 0.6514/23 [=================>............] - ETA: 0s - loss: 0.5030 - accuracy: 0.7423/23 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7560 - val_loss: 0.4818 - val_accuracy: 0.7697\nEpoch 43/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5843 - accuracy: 0.6511/23 [=============>................] - ETA: 0s - loss: 0.5011 - accuracy: 0.7423/23 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7546 - val_loss: 0.4833 - val_accuracy: 0.7697\nEpoch 44/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5778 - accuracy: 0.65 2/23 [=>............................] - ETA: 0s - loss: 0.5360 - accuracy: 0.6410/23 [============>.................] - ETA: 0s - loss: 0.4977 - accuracy: 0.7517/23 [=====================>........] - ETA: 0s - loss: 0.4841 - accuracy: 0.7623/23 [==============================] - 0s 12ms/step - loss: 0.4970 - accuracy: 0.7630 - val_loss: 0.4833 - val_accuracy: 0.7697\nEpoch 45/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5743 - accuracy: 0.6516/23 [===================>..........] - ETA: 0s - loss: 0.4876 - accuracy: 0.7623/23 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7602 - val_loss: 0.4833 - val_accuracy: 0.7753\nEpoch 46/1000\n 1/23 [>.............................] - ETA: 0s - loss: 0.5654 - accuracy: 0.6815/23 [==================>...........] - ETA: 0s - loss: 0.4864 - accuracy: 0.7623/23 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7714 - val_loss: 0.4853 - val_accuracy: 0.7753\n"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 17f0681960a20b877624922a6bcee13a</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.7752808928489685</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-optimizer: adam</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/dropout_rate: 0</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/num_layers: 2</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/units_0: 32</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:blue\"> |-structured_data_block_1/dense_block_1/units_1: 32</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<span style=\"color:cyan\"> |-structured_data_block_1/dense_block_1/use_batchnorm: False</span>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".................] - ETA: 0s - loss: 0.6618 - accuracy: 0.6914/29 [=============>................] - ETA: 0s - loss: 0.6597 - accuracy: 0.7128/29 [===========================>..] - ETA: 0s - loss: 0.6191 - accuracy: 0.7229/29 [==============================] - 0s 9ms/step - loss: 0.6175 - accuracy: 0.7239 - val_loss: 0.4476 - val_accuracy: 0.7753\nEpoch 28/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5998 - accuracy: 0.6514/29 [=============>................] - ETA: 0s - loss: 0.6638 - accuracy: 0.7029/29 [==============================] - 0s 6ms/step - loss: 0.6180 - accuracy: 0.7205 - val_loss: 0.4455 - val_accuracy: 0.7697\nEpoch 29/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6007 - accuracy: 0.6516/29 [===============>..............] - ETA: 0s - loss: 0.6492 - accuracy: 0.7121/29 [====================>.........] - ETA: 0s - loss: 0.6202 - accuracy: 0.7229/29 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.7239 - val_loss: 0.4417 - val_accuracy: 0.7753\nEpoch 30/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.6026 - accuracy: 0.65 8/29 [=======>......................] - ETA: 0s - loss: 0.6537 - accuracy: 0.7318/29 [=================>............] - ETA: 0s - loss: 0.6353 - accuracy: 0.7227/29 [==========================>...] - ETA: 0s - loss: 0.6138 - accuracy: 0.7229/29 [==============================] - 0s 8ms/step - loss: 0.6098 - accuracy: 0.7284 - val_loss: 0.4431 - val_accuracy: 0.7753\nEpoch 31/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5926 - accuracy: 0.6512/29 [===========>..................] - ETA: 0s - loss: 0.6343 - accuracy: 0.7221/29 [====================>.........] - ETA: 0s - loss: 0.6140 - accuracy: 0.7329/29 [==============================] - 0s 9ms/step - loss: 0.6073 - accuracy: 0.7284 - val_loss: 0.4434 - val_accuracy: 0.7753\nEpoch 32/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5973 - accuracy: 0.6511/29 [==========>...................] - ETA: 0s - loss: 0.6522 - accuracy: 0.7127/29 [==========================>...] - ETA: 0s - loss: 0.6096 - accuracy: 0.7229/29 [==============================] - 0s 7ms/step - loss: 0.6056 - accuracy: 0.7262 - val_loss: 0.4412 - val_accuracy: 0.7753\nEpoch 33/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5958 - accuracy: 0.6517/29 [================>.............] - ETA: 0s - loss: 0.6296 - accuracy: 0.7225/29 [========================>.....] - ETA: 0s - loss: 0.6107 - accuracy: 0.7229/29 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.7273 - val_loss: 0.4398 - val_accuracy: 0.7753\nEpoch 34/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.6012 - accuracy: 0.6517/29 [================>.............] - ETA: 0s - loss: 0.6261 - accuracy: 0.7227/29 [==========================>...] - ETA: 0s - loss: 0.6026 - accuracy: 0.7329/29 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.7306 - val_loss: 0.4403 - val_accuracy: 0.7753\nEpoch 35/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5901 - accuracy: 0.65 4/29 [===>..........................] - ETA: 0s - loss: 0.6404 - accuracy: 0.6821/29 [====================>.........] - ETA: 0s - loss: 0.6008 - accuracy: 0.7329/29 [==============================] - 0s 7ms/step - loss: 0.5949 - accuracy: 0.7306 - val_loss: 0.4377 - val_accuracy: 0.7753\nEpoch 36/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5980 - accuracy: 0.6812/29 [===========>..................] - ETA: 0s - loss: 0.6180 - accuracy: 0.7325/29 [========================>.....] - ETA: 0s - loss: 0.6005 - accuracy: 0.7228/29 [===========================>..] - ETA: 0s - loss: 0.5948 - accuracy: 0.7329/29 [==============================] - 0s 8ms/step - loss: 0.5930 - accuracy: 0.7318 - val_loss: 0.4374 - val_accuracy: 0.7809\nEpoch 37/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5884 - accuracy: 0.68 8/29 [=======>......................] - ETA: 0s - loss: 0.6295 - accuracy: 0.7321/29 [====================>.........] - ETA: 0s - loss: 0.5959 - accuracy: 0.7327/29 [==========================>...] - ETA: 0s - loss: 0.5951 - accuracy: 0.7329/29 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.7340 - val_loss: 0.4391 - val_accuracy: 0.7753\nEpoch 38/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5948 - accuracy: 0.6515/29 [==============>...............] - ETA: 0s - loss: 0.6295 - accuracy: 0.7221/29 [====================>.........] - ETA: 0s - loss: 0.5963 - accuracy: 0.7329/29 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.7329 - val_loss: 0.4376 - val_accuracy: 0.7753\nEpoch 39/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5935 - accuracy: 0.65 8/29 [=======>......................] - ETA: 0s - loss: 0.6260 - accuracy: 0.7221/29 [====================>.........] - ETA: 0s - loss: 0.5920 - accuracy: 0.7327/29 [==========================>...] - ETA: 0s - loss: 0.5907 - accuracy: 0.7329/29 [==============================] - 0s 9ms/step - loss: 0.5867 - accuracy: 0.7329 - val_loss: 0.4361 - val_accuracy: 0.7753\nEpoch 40/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5950 - accuracy: 0.6814/29 [=============>................] - ETA: 0s - loss: 0.6212 - accuracy: 0.7323/29 [======================>.......] - ETA: 0s - loss: 0.5902 - accuracy: 0.7428/29 [===========================>..] - ETA: 0s - loss: 0.5861 - accuracy: 0.7429/29 [==============================] - 0s 9ms/step - loss: 0.5843 - accuracy: 0.7385 - val_loss: 0.4360 - val_accuracy: 0.7753\nEpoch 41/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5887 - accuracy: 0.6815/29 [==============>...............] - ETA: 0s - loss: 0.6179 - accuracy: 0.7323/29 [======================>.......] - ETA: 0s - loss: 0.5876 - accuracy: 0.7429/29 [==============================] - 0s 7ms/step - loss: 0.5829 - accuracy: 0.7419 - val_loss: 0.4373 - val_accuracy: 0.7697\nEpoch 42/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5907 - accuracy: 0.6815/29 [==============>...............] - ETA: 0s - loss: 0.6192 - accuracy: 0.7324/29 [=======================>......] - ETA: 0s - loss: 0.5826 - accuracy: 0.7429/29 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.7419 - val_loss: 0.4373 - val_accuracy: 0.7753\nEpoch 43/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6011 - accuracy: 0.6812/29 [===========>..................] - ETA: 0s - loss: 0.5986 - accuracy: 0.7419/29 [==================>...........] - ETA: 0s - loss: 0.5880 - accuracy: 0.7429/29 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.7407 - val_loss: 0.4331 - val_accuracy: 0.7809\nEpoch 44/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5929 - accuracy: 0.68 8/29 [=======>......................] - ETA: 0s - loss: 0.6143 - accuracy: 0.7323/29 [======================>.......] - ETA: 0s - loss: 0.5817 - accuracy: 0.7429/29 [==============================] - 0s 7ms/step - loss: 0.5770 - accuracy: 0.7419 - val_loss: 0.4352 - val_accuracy: 0.7809\nEpoch 45/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5902 - accuracy: 0.68 9/29 [========>.....................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7421/29 [====================>.........] - ETA: 0s - loss: 0.5795 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5755 - accuracy: 0.7452 - val_loss: 0.4370 - val_accuracy: 0.7753\nEpoch 46/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5963 - accuracy: 0.7113/29 [============>.................] - ETA: 0s - loss: 0.5873 - accuracy: 0.7428/29 [===========================>..] - ETA: 0s - loss: 0.5733 - accuracy: 0.7429/29 [==============================] - 0s 7ms/step - loss: 0.5712 - accuracy: 0.7441 - val_loss: 0.4317 - val_accuracy: 0.7809\nEpoch 47/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5968 - accuracy: 0.6814/29 [=============>................] - ETA: 0s - loss: 0.6048 - accuracy: 0.7322/29 [=====================>........] - ETA: 0s - loss: 0.5693 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.7452 - val_loss: 0.4372 - val_accuracy: 0.7865\nEpoch 48/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5849 - accuracy: 0.7514/29 [=============>................] - ETA: 0s - loss: 0.6073 - accuracy: 0.7424/29 [=======================>......] - ETA: 0s - loss: 0.5727 - accuracy: 0.7529/29 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.7520 - val_loss: 0.4365 - val_accuracy: 0.7865\nEpoch 49/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5995 - accuracy: 0.6817/29 [================>.............] - ETA: 0s - loss: 0.5875 - accuracy: 0.7426/29 [=========================>....] - ETA: 0s - loss: 0.5695 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5661 - accuracy: 0.7520 - val_loss: 0.4340 - val_accuracy: 0.7921\nEpoch 50/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5991 - accuracy: 0.71 9/29 [========>.....................] - ETA: 0s - loss: 0.5787 - accuracy: 0.7519/29 [==================>...........] - ETA: 0s - loss: 0.5732 - accuracy: 0.7527/29 [==========================>...] - ETA: 0s - loss: 0.5678 - accuracy: 0.7529/29 [==============================] - 0s 8ms/step - loss: 0.5642 - accuracy: 0.7531 - val_loss: 0.4323 - val_accuracy: 0.7921\nEpoch 51/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5894 - accuracy: 0.7514/29 [=============>................] - ETA: 0s - loss: 0.5961 - accuracy: 0.7418/29 [=================>............] - ETA: 0s - loss: 0.5830 - accuracy: 0.7529/29 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.7542 - val_loss: 0.4343 - val_accuracy: 0.7865\nEpoch 52/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5941 - accuracy: 0.7514/29 [=============>................] - ETA: 0s - loss: 0.5925 - accuracy: 0.7428/29 [===========================>..] - ETA: 0s - loss: 0.5632 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7542 - val_loss: 0.4327 - val_accuracy: 0.7921\nEpoch 53/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5940 - accuracy: 0.7112/29 [===========>..................] - ETA: 0s - loss: 0.5751 - accuracy: 0.7429/29 [==============================] - 0s 6ms/step - loss: 0.5596 - accuracy: 0.7542 - val_loss: 0.4326 - val_accuracy: 0.7978\nEpoch 54/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5993 - accuracy: 0.6817/29 [================>.............] - ETA: 0s - loss: 0.5773 - accuracy: 0.7420/29 [===================>..........] - ETA: 0s - loss: 0.5580 - accuracy: 0.7525/29 [========================>.....] - ETA: 0s - loss: 0.5630 - accuracy: 0.7429/29 [==============================] - 0s 8ms/step - loss: 0.5584 - accuracy: 0.7520 - val_loss: 0.4317 - val_accuracy: 0.7978\nEpoch 55/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5913 - accuracy: 0.7114/29 [=============>................] - ETA: 0s - loss: 0.5908 - accuracy: 0.7427/29 [==========================>...] - ETA: 0s - loss: 0.5634 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7565 - val_loss: 0.4332 - val_accuracy: 0.7978\nEpoch 56/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5938 - accuracy: 0.7113/29 [============>.................] - ETA: 0s - loss: 0.5677 - accuracy: 0.7516/29 [===============>..............] - ETA: 0s - loss: 0.5808 - accuracy: 0.7429/29 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7565 - val_loss: 0.4301 - val_accuracy: 0.7978\nEpoch 57/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5997 - accuracy: 0.68 9/29 [========>.....................] - ETA: 0s - loss: 0.5666 - accuracy: 0.7423/29 [======================>.......] - ETA: 0s - loss: 0.5546 - accuracy: 0.7629/29 [==============================] - 0s 7ms/step - loss: 0.5526 - accuracy: 0.7576 - val_loss: 0.4329 - val_accuracy: 0.7978\nEpoch 58/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5953 - accuracy: 0.6812/29 [===========>..................] - ETA: 0s - loss: 0.5662 - accuracy: 0.7423/29 [======================>.......] - ETA: 0s - loss: 0.5558 - accuracy: 0.7529/29 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7542 - val_loss: 0.4309 - val_accuracy: 0.7978\nEpoch 59/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5952 - accuracy: 0.7112/29 [===========>..................] - ETA: 0s - loss: 0.5685 - accuracy: 0.7422/29 [=====================>........] - ETA: 0s - loss: 0.5503 - accuracy: 0.7629/29 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.7587 - val_loss: 0.4313 - val_accuracy: 0.7978\nEpoch 60/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5935 - accuracy: 0.71 9/29 [========>.....................] - ETA: 0s - loss: 0.5647 - accuracy: 0.7521/29 [====================>.........] - ETA: 0s - loss: 0.5509 - accuracy: 0.7629/29 [==============================] - 0s 7ms/step - loss: 0.5492 - accuracy: 0.7587 - val_loss: 0.4308 - val_accuracy: 0.7978\nEpoch 61/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5949 - accuracy: 0.7116/29 [===============>..............] - ETA: 0s - loss: 0.5696 - accuracy: 0.7425/29 [========================>.....] - ETA: 0s - loss: 0.5509 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5472 - accuracy: 0.7576 - val_loss: 0.4320 - val_accuracy: 0.7921\nEpoch 62/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5987 - accuracy: 0.6815/29 [==============>...............] - ETA: 0s - loss: 0.5733 - accuracy: 0.7427/29 [==========================>...] - ETA: 0s - loss: 0.5522 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5487 - accuracy: 0.7531 - val_loss: 0.4312 - val_accuracy: 0.7865\nEpoch 63/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5915 - accuracy: 0.7116/29 [===============>..............] - ETA: 0s - loss: 0.5752 - accuracy: 0.7424/29 [=======================>......] - ETA: 0s - loss: 0.5474 - accuracy: 0.7629/29 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7576 - val_loss: 0.4330 - val_accuracy: 0.7921\nEpoch 64/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5932 - accuracy: 0.7113/29 [============>.................] - ETA: 0s - loss: 0.5557 - accuracy: 0.7426/29 [=========================>....] - ETA: 0s - loss: 0.5482 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7565 - val_loss: 0.4324 - val_accuracy: 0.7865\nEpoch 65/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5979 - accuracy: 0.71 2/29 [=>............................] - ETA: 2s - loss: 0.5838 - accuracy: 0.7011/29 [==========>...................] - ETA: 0s - loss: 0.5732 - accuracy: 0.7315/29 [==============>...............] - ETA: 0s - loss: 0.5694 - accuracy: 0.7424/29 [=======================>......] - ETA: 0s - loss: 0.5409 - accuracy: 0.7629/29 [==============================] - 0s 14ms/step - loss: 0.5445 - accuracy: 0.7565 - val_loss: 0.4324 - val_accuracy: 0.7865\nEpoch 66/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.6023 - accuracy: 0.7113/29 [============>.................] - ETA: 0s - loss: 0.5530 - accuracy: 0.7419/29 [==================>...........] - ETA: 0s - loss: 0.5501 - accuracy: 0.7529/29 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7542 - val_loss: 0.4298 - val_accuracy: 0.7865\nEpoch 67/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5944 - accuracy: 0.71 9/29 [========>.....................] - ETA: 0s - loss: 0.5614 - accuracy: 0.7525/29 [========================>.....] - ETA: 0s - loss: 0.5492 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.7587 - val_loss: 0.4311 - val_accuracy: 0.7809\nEpoch 68/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5934 - accuracy: 0.7118/29 [=================>............] - ETA: 0s - loss: 0.5557 - accuracy: 0.7523/29 [======================>.......] - ETA: 0s - loss: 0.5431 - accuracy: 0.7529/29 [==============================] - 0s 8ms/step - loss: 0.5403 - accuracy: 0.7576 - val_loss: 0.4315 - val_accuracy: 0.7809\nEpoch 69/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5972 - accuracy: 0.7516/29 [===============>..............] - ETA: 0s - loss: 0.5588 - accuracy: 0.7421/29 [====================>.........] - ETA: 0s - loss: 0.5374 - accuracy: 0.7629/29 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7587 - val_loss: 0.4319 - val_accuracy: 0.7809\nEpoch 70/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6000 - accuracy: 0.7112/29 [===========>..................] - ETA: 0s - loss: 0.5472 - accuracy: 0.7425/29 [========================>.....] - ETA: 0s - loss: 0.5438 - accuracy: 0.7529/29 [==============================] - 0s 7ms/step - loss: 0.5409 - accuracy: 0.7553 - val_loss: 0.4314 - val_accuracy: 0.7809\nEpoch 71/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5917 - accuracy: 0.75 6/29 [=====>........................] - ETA: 0s - loss: 0.5683 - accuracy: 0.7317/29 [================>.............] - ETA: 0s - loss: 0.5588 - accuracy: 0.7525/29 [========================>.....] - ETA: 0s - loss: 0.5469 - accuracy: 0.7529/29 [==============================] - 0s 10ms/step - loss: 0.5427 - accuracy: 0.7587 - val_loss: 0.4343 - val_accuracy: 0.7809\nEpoch 72/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5951 - accuracy: 0.7510/29 [=========>....................] - ETA: 0s - loss: 0.5605 - accuracy: 0.7514/29 [=============>................] - ETA: 0s - loss: 0.5627 - accuracy: 0.7527/29 [==========================>...] - ETA: 0s - loss: 0.5426 - accuracy: 0.7629/29 [==============================] - 0s 10ms/step - loss: 0.5387 - accuracy: 0.7609 - val_loss: 0.4337 - val_accuracy: 0.7865\nEpoch 73/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5987 - accuracy: 0.7517/29 [================>.............] - ETA: 0s - loss: 0.5505 - accuracy: 0.7522/29 [=====================>........] - ETA: 0s - loss: 0.5308 - accuracy: 0.7628/29 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7629/29 [==============================] - 0s 10ms/step - loss: 0.5374 - accuracy: 0.7609 - val_loss: 0.4330 - val_accuracy: 0.7809\nEpoch 74/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.6064 - accuracy: 0.6816/29 [===============>..............] - ETA: 0s - loss: 0.5566 - accuracy: 0.7424/29 [=======================>......] - ETA: 0s - loss: 0.5327 - accuracy: 0.7629/29 [==============================] - 0s 7ms/step - loss: 0.5368 - accuracy: 0.7576 - val_loss: 0.4304 - val_accuracy: 0.7809\nEpoch 75/1000\n 1/29 [>.............................] - ETA: 0s - loss: 0.5963 - accuracy: 0.7110/29 [=========>....................] - ETA: 0s - loss: 0.5588 - accuracy: 0.7513/29 [============>.................] - ETA: 0s - loss: 0.5452 - accuracy: 0.7528/29 [===========================>..] - ETA: 0s - loss: 0.5386 - accuracy: 0.7629/29 [==============================] - 0s 9ms/step - loss: 0.5366 - accuracy: 0.7621 - val_loss: 0.4325 - val_accuracy: 0.7809\nEpoch 76/1000\n 1/29 [>.............................] - ETA: 1s - loss: 0.5945 - accuracy: 0.7117/29 [================>.............] - ETA: 0s - loss: 0.5461 - accuracy: 0.7526/29 [=========================>....] - ETA: 0s - loss: 0.5357 - accuracy: 0.7629/29 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.7621 - val_loss: 0.4338 - val_accuracy: 0.7865\n"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "# Initialize the structured data classifier.\n",
    "clf = ak.StructuredDataClassifier(max_trials=1) # It tries 1 different models.\n",
    "# Feed the structured data classifier with training data.\n",
    "train_y = df_train.pop('Survived')\n",
    "clf.fit(x=df_train,y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv(\"./titanic/gender_submission.csv\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['Survived'] = preds\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"./titanic_submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}